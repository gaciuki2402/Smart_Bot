{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1faP-MTwUuqUapBzVyDEW2GMEIheEHhky",
      "authorship_tag": "ABX9TyPBZ0Lp/ShHzoYYe8BvAWr7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gaciuki2402/Smart_Bot/blob/main/NLTPK_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "noUmxDO4XdY2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "import string\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SUMV9RuXyOI",
        "outputId": "ffab67f7-5912-4e25-a26e-6cf7c1447d3a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reading the corpus of text**"
      ],
      "metadata": {
        "id": "MyKYARmH4sak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('/data.txt', 'r', errors = 'ignore')\n",
        "raw_doc = f.read()"
      ],
      "metadata": {
        "id": "p4Ok2-fs3hdD"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_doc = raw_doc.lower()#converting entire text to lowercase\n",
        "nltk.download('punkt')#downloading the punkt tokenizer for sentence tokenization\n",
        "nltk.download('wordnet')#downloading the wordnet dictionary for lemmatization\n",
        "nltk.download('omw-1.4')\n",
        "sentence_tokens = nltk.sent_tokenize(raw_doc)#converting the entire text into a list of sentences\n",
        "word_tokens = nltk.word_tokenize(raw_doc)#converting the entire text into a list of words\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyU3Z7fD3hln",
        "outputId": "8f0c36ca-6008-4f1d-fe3f-b7263ce9c0ae"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_tokens = nltk.sent_tokenize(raw_doc)\n",
        "word_tokens = nltk.word_tokenize(raw_doc)"
      ],
      "metadata": {
        "id": "zDDT6stx3hqn"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_tokens[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Tb5ZJF66X9Q",
        "outputId": "32d46592-1874-4cb2-904c-eab5d980f92c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\nmain menu\\n\\nwikipediathe free encyclopedia\\nsearch\\n\\nappearance\\n\\npersonal tools\\nlogo africa wiki challenge\\t\\njoin the africa wiki challenge\\nmay 25th to 30th june, 2024\\ntheme: educate africa: nurturing minds for the 21st century\\n\\nlogo open foundation africa\\n\\ntoggle the table of contents\\ncontents\\n(top)\\nbackground\\ndevelopment\\napplication\\ntoggle application subsection\\nmessaging apps\\nas part of company apps and websites\\nchatbot sequences\\ncompany internal platforms\\ncustomer service\\nhealthcare\\npolitics\\ngovernment\\ntoys\\nmalicious use\\ndata security\\nlimitations of chatbots\\nchatbots and jobs\\nsee also\\nreferences\\nfurther reading\\nexternal links\\nchatbot\\n\\narticle\\ntalk\\n\\ntools\\nfrom wikipedia, the free encyclopedia\\nfor the bot-creation software, see chatbot.',\n",
              " 'for bots on internet relay chat, see irc bot.',\n",
              " 'parts of this article (those related to everything, particularly sections after the intro) need to be updated.',\n",
              " 'the reason given is: this article is using citations from 1970 and virtually all claims about conversational capabilities are at least ten years out of date (for example the turing test was arguably made obsolete years ago by transformer models).',\n",
              " 'please help update this article to reflect recent events or newly available information.']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokens[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhwRHfLM6YGT",
        "outputId": "93b16c7f-c3d3-4126-d722-0ae94fbea58e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['main', 'menu', 'wikipediathe', 'free', 'encyclopedia']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Performing Text-PreProcessing Steps**"
      ],
      "metadata": {
        "id": "0v8n8bHj7Bms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmer = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "# Defining punctuation removal dictionary\n",
        "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
        "\n",
        "def LemTokens(tokens):\n",
        "    return [lemmer.lemmatize(token) for token in tokens]\n",
        "    remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
        "def LemNormalize(text):\n",
        "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
      ],
      "metadata": {
        "id": "LXk3Iog-67fQ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Greetinggs Functions**"
      ],
      "metadata": {
        "id": "c1HPjuxE7qnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "greet_inputs = ('hello', 'hi', 'greetings', 'sup', 'what\\'s up','hey', 'how are you?')\n",
        "greet_responses = ('hi', 'hey', 'hi there', 'hello', 'I am glad! You are talking to me')\n",
        "def greet(sentence):\n",
        "    for word in sentence.split():\n",
        "        if word.lower() in greet_inputs:\n",
        "            return random.choice(greet_responses)"
      ],
      "metadata": {
        "id": "J_a4hZBV676y"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Respose Generation by the Bot**"
      ],
      "metadata": {
        "id": "7DUuOepu8PoE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "oxDAWBdw8Vid"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def response(user_response):\n",
        "  robo1_response = ''\n",
        "  TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
        "  tfidf = TfidfVec.fit_transform(sentence_tokens)\n",
        "  vals = cosine_similarity(tfidf[-1], tfidf)\n",
        "  idx = vals.argsort()[0][-2]\n",
        "  flat = vals.flatten()\n",
        "  flat.sort()\n",
        "  req_tfidf = flat[-2]\n",
        "  if(req_tfidf == 0):\n",
        "    robo1_response = robo1_response + \"I am sorry! I don't understand you\"\n",
        "    return robo1_response\n",
        "  else:\n",
        "    robo1_response = robo1_response + sentence_tokens[idx]\n",
        "    return robo1_response"
      ],
      "metadata": {
        "id": "DGFnjpv58Wc8"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining the ChatFlow**"
      ],
      "metadata": {
        "id": "vD7syAS29xZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flag = True\n",
        "print(\"Hello! My name is Robo. Let's have a conversation! Also, if you want to exit any time, just type Bye!\")\n",
        "while(flag == True):\n",
        "  user_response = input()\n",
        "  user_response = user_response.lower()\n",
        "  if user_response == 'bye':\n",
        "        flag = False\n",
        "        print('Bot: Goodbye')\n",
        "  elif (user_response == 'thank you' or user_response == 'thanks'):\n",
        "    flag = False\n",
        "    print('Bot: You are welcome..')\n",
        "  else:\n",
        "    if(greet(user_response) !=None):\n",
        "      print('Bot: ' + greet(user_response))\n",
        "    else:\n",
        "      sentence_tokens.append(user_response)\n",
        "      word_tokens = word_tokens + nltk.word_tokenize(user_response)\n",
        "      final_words = list(set(word_tokens))\n",
        "      print(\"Bot: \", end= \"\")\n",
        "      print(response(user_response))\n",
        "      sentence_tokens.remove(user_response)\n",
        "else:\n",
        "  flag = False\n",
        "  print('Bot: Goodbye')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFJjRe_q7bq1",
        "outputId": "c9cda76e-3d38-43e9-bc33-dc05d810547c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! My name is Robo. Let's have a conversation! Also, if you want to exit any time, just type Bye!\n",
            "hi\n",
            "Bot: hello\n",
            "tell me about turing test\n",
            "Bot: chatbot competitions focus on the turing test or more specific goals.\n",
            "bye\n",
            "Bot: Goodbye\n",
            "Bot: Goodbye\n"
          ]
        }
      ]
    }
  ]
}